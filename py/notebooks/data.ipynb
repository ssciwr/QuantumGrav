{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.loader import DataLoader \n",
    "import torch_geometric.transforms as tgt\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.utils import scatter\n",
    "from functools import lru_cache\n",
    "\n",
    "import h5py\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "We first need to implement a data loader to get the data from the hdf5 files. I can do a lot of stuff that I until now have done in Julia with pytorch-geometric, e.g., graph laplacians and shit like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this function is too long, break it up into smaller ones\n",
    "\n",
    "def load_graph(\n",
    "    f: h5py.File, idx: int, float_dtype: torch.dtype, int_dtype: torch.dtype, validate:bool = False\n",
    ") -> Data:\n",
    "    # Load adjacency matrix and convert to edge indices\n",
    "    adj_matrix = torch.tensor(f[\"adjacency_matrix\"][:, :, idx], dtype=float_dtype)\n",
    "    edge_index, edge_weight = dense_to_sparse(adj_matrix)\n",
    "    adj_matrix = adj_matrix.to_sparse()\n",
    "    # Load node features\n",
    "    node_features = []\n",
    "\n",
    "    # Sprinkling coordinates\n",
    "    # sprinkling = torch.tensor(f[\"sprinkling\"][:, :, idx], dtype=float_dtype)\n",
    "\n",
    "    # node_features.append(sprinkling)\n",
    "\n",
    "    # Degree information\n",
    "    in_degrees = torch.tensor(f[\"in_degrees\"][:, idx], dtype=float_dtype).unsqueeze(1)\n",
    "    out_degrees = torch.tensor(f[\"out_degrees\"][:, idx], dtype=float_dtype).unsqueeze(1)\n",
    "    node_features.extend([in_degrees, out_degrees])\n",
    "\n",
    "    # Path lengths\n",
    "    max_path_future = torch.tensor(\n",
    "        f[\"max_path_lengths_future\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    max_path_past = torch.tensor(\n",
    "        f[\"max_path_lengths_past\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    node_features.extend([max_path_future, max_path_past])\n",
    "\n",
    "    # Link-based path lengths\n",
    "    max_path_future_links = torch.tensor(\n",
    "        f[\"max_path_lengths_future_links\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    max_path_past_links = torch.tensor(\n",
    "        f[\"max_path_lengths_past_links\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    node_features.extend([max_path_future_links, max_path_past_links])\n",
    "\n",
    "    # Topological ordering --> TODO: check again what this does\n",
    "    topo_future = torch.tensor(\n",
    "        f[\"topological_order_future\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    topo_past = torch.tensor(\n",
    "        f[\"topological_order_past\"][:, idx], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    node_features.extend([topo_future, topo_past])\n",
    "\n",
    "    # Concatenate all node features\n",
    "    x = torch.cat(node_features, dim=1)\n",
    "\n",
    "    # Load graph-level features (targets for regression)\n",
    "    manifold_id = torch.tensor(f[\"manifold_ids\"][idx], dtype=int_dtype)\n",
    "    boundary_id = torch.tensor(f[\"boundary_ids\"][idx], dtype=int_dtype)\n",
    "    relation_dim = torch.tensor(f[\"relation_dim\"][idx], dtype=float_dtype)\n",
    "    atom_count = torch.tensor(f[\"atom_count\"][idx], dtype=int_dtype)\n",
    "    num_sources = torch.tensor(f[\"num_sources\"][idx], dtype=int_dtype)\n",
    "    num_sinks = torch.tensor(f[\"num_sinks\"][idx], dtype=int_dtype)\n",
    "    dimension = torch.tensor(f[\"dimension\"][idx], dtype=int_dtype)\n",
    "\n",
    "    # matrices\n",
    "    link_matrix = torch.tensor(f[\"link_matrix\"][:, :, idx], dtype=float_dtype).to_sparse()\n",
    "    past_relations = torch.tensor(f[\"past_relations\"][:, :, idx], dtype=float_dtype).to_sparse()\n",
    "    future_relations = torch.tensor(f[\"future_relations\"][:, :, idx], dtype=float_dtype).to_sparse()\n",
    "\n",
    "    # Create Data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_weight.unsqueeze(1)\n",
    "        if edge_weight.numel() > 0\n",
    "        else None,  # Not sure if this is a good idea need to add edge attributes if possible\n",
    "\n",
    "        # node positions as positional attributes as well\n",
    "        # pos=sprinkling,\n",
    "\n",
    "        y = torch.tensor([manifold_id[0], boundary_id[0], dimension[0]]),\n",
    "\n",
    "        # Graph-level attributes\n",
    "        manifold_id=manifold_id,\n",
    "        boundary_id=boundary_id,\n",
    "        relation_dim=relation_dim,\n",
    "        dimension=dimension,\n",
    "        atom_count=atom_count,\n",
    "        num_sources=num_sources,\n",
    "        num_sinks=num_sinks,\n",
    "        # sprinkling=sprinkling,\n",
    "        \n",
    "        # Additional matrices as graph attributes. make the shitty past and future relations and all that into node attributes!\n",
    "        adjacency_matrix=adj_matrix,\n",
    "        link_matrix=link_matrix,\n",
    "        past_relations=past_relations,\n",
    "        future_relations=future_relations,\n",
    "    )\n",
    "\n",
    "    if validate:\n",
    "        data.validate()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input: list[str],\n",
    "        output: str,\n",
    "        transform: callable | None = None,\n",
    "        pre_transform: callable | None = None,\n",
    "        pre_filter: callable | None = None,\n",
    "        validate_data: bool = False,\n",
    "    ):\n",
    "        super().__init__(output, transform, pre_transform, pre_filter)\n",
    "        self.input = input\n",
    "        self._num_samples = None\n",
    "        self.validate_data = validate_data\n",
    "        \n",
    "        with h5py.File(input, \"r\") as f:\n",
    "            self.dimension = f[\"dimension\"]\n",
    "            self.manifold_codes = f[\"manifold_codes\"]\n",
    "            self.manifold_names = f[\"manifold_names\"]\n",
    "            self.boundaries = f[\"boundaries\"]\n",
    "            self.boundary_codes = f[\"boundary_codes\"]\n",
    "            self._num_samples = f[\"num_causal_sets\"]\n",
    "\n",
    "    @property\n",
    "    def raw_paths(self):\n",
    "        return self.input\n",
    "\n",
    "    @property\n",
    "    def output(self):\n",
    "        return self.root\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [os.path.basename(self.input)]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f for f in os.listdir(self.root) if f.startswith(\"data_\") and f.endswith(\".pt\")]\n",
    "\n",
    "    def process(self):\n",
    "        for file in self.raw_paths:\n",
    "            if not os.path.exists(file):\n",
    "                raise FileNotFoundError(f\"Input file {file} does not exist.\")\n",
    "            with h5py.File(file, \"r\") as f:\n",
    "                for idx in range(self.len()): \n",
    "                    data = load_graph(f, idx, float_dtype=torch.float32, int_dtype=torch.int64, validate=self.validate_data)\n",
    "\n",
    "                    if self.pre_filter is not None: \n",
    "                        if not self.pre_filter(data):\n",
    "                            continue\n",
    "                    if self.pre_transform is not None:\n",
    "                        data = self.pre_transform(data)\n",
    "                    torch.save(data, os.path.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
    "\n",
    "    def len(self):\n",
    "        return self._num_samples\n",
    "\n",
    "    @lru_cache(maxsize=100) # cache some results for faster access\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f\"data_{idx}.pt\"))\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        return data\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
