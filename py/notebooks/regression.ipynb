{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.loader import DataLoader \n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from functools import lru_cache\n",
    "from collections.abc import Callable\n",
    "import concurrent.futures \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "optimizations: \n",
    "- load a batch of data for all datasets\n",
    "- process them in parallel \n",
    "- then load the next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: this function is too long, break it up into smaller ones\n",
    "\n",
    "\n",
    "def load_graph(\n",
    "    f: h5py.File,\n",
    "    idx: int,\n",
    "    float_dtype: torch.dtype,\n",
    "    int_dtype: torch.dtype,\n",
    "    validate: bool = False,\n",
    ") -> Data:\n",
    "    \n",
    "    # print(f\"  Loading graph at index {idx}...\")\n",
    "    # Load adjacency matrix and convert to edge indices\n",
    "    # print(\"  Data shapes: \")\n",
    "    # print(f\"   Adjacency matrix data shape: {f['adjacency_matrix'].shape}\")\n",
    "    # print(f\"   link matrix data shape: {f['link_matrix'].shape}\")\n",
    "    # print(f\"   past_relations data shape: {f['past_relations'].shape}\")\n",
    "    # print(f\"   future_relations data shape: {f['future_relations'].shape}\")\n",
    "    # print(f\"   in_degrees data shape: {f['in_degrees'].shape}\")\n",
    "    # print(f\"   out_degrees data shape: {f['out_degrees'].shape}\")\n",
    "    # print(f\"   max_path_lengths_future data shape: {f['max_path_lengths_future'].shape}\")\n",
    "    # print(f\"   max_path_lengths_past data shape: {f['max_path_lengths_past'].shape}\")\n",
    "    # print(f\"   Adjacency matrix data shape: {f['adjacency_matrix'].shape}\")\n",
    "\n",
    "    adj_raw = f[\"adjacency_matrix\"][idx, :, :]\n",
    "    # print(' raw adjacency matrix shape:', adj_raw.shape)\n",
    "    adj_matrix = torch.tensor(adj_raw, dtype=float_dtype)\n",
    "    # print('  Converting adjacency matrix to edge indices...')\n",
    "    edge_index, edge_weight = dense_to_sparse(adj_matrix)\n",
    "    # print('  Converting adjacency matrix to sparse format...')\n",
    "    adj_matrix = adj_matrix.to_sparse()\n",
    "    \n",
    "    # print('  Loading node features...')\n",
    "    # Load node features\n",
    "    node_features = []\n",
    "\n",
    "    # Sprinkling coordinates\n",
    "    # sprinkling = torch.tensor(f[\"sprinkling\"][idx, :, :], dtype=float_dtype)\n",
    "\n",
    "    # node_features.append(sprinkling)\n",
    "\n",
    "    # Degree information\n",
    "    in_degrees = torch.tensor(f[\"in_degrees\"][idx,:], dtype=float_dtype).unsqueeze(1)\n",
    "    out_degrees = torch.tensor(f[\"out_degrees\"][idx,:], dtype=float_dtype).unsqueeze(1)\n",
    "    node_features.extend([in_degrees, out_degrees])\n",
    "\n",
    "    # Path lengths\n",
    "    max_path_future = torch.tensor(\n",
    "        f[\"max_path_lengths_future\"][idx,:], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    max_path_past = torch.tensor(\n",
    "        f[\"max_path_lengths_past\"][idx,:], dtype=float_dtype\n",
    "    ).unsqueeze(1)\n",
    "    node_features.extend([max_path_future, max_path_past])\n",
    "\n",
    "    # I need more topological information here - angles, etc.\n",
    "    # Link-based path lengths\n",
    "    # max_path_future_links = torch.tensor(\n",
    "    #     f[\"max_path_lengths_future_links\"][idx,:], dtype=float_dtype\n",
    "    # ).unsqueeze(1)\n",
    "    # max_path_past_links = torch.tensor(\n",
    "    #     f[\"max_path_lengths_past_links\"][idx,:], dtype=float_dtype\n",
    "    # ).unsqueeze(1)\n",
    "    # node_features.extend([max_path_future_links, max_path_past_links])\n",
    "\n",
    "    # # Topological ordering --> TODO: check again what this does\n",
    "    # topo_future = torch.tensor(\n",
    "    #     f[\"topological_order_future\"][idx,:], dtype=float_dtype\n",
    "    # ).unsqueeze(1)\n",
    "    # topo_past = torch.tensor(\n",
    "    #     f[\"topological_order_past\"][idx,:], dtype=float_dtype\n",
    "    # ).unsqueeze(1)\n",
    "    # node_features.extend([topo_future, topo_past])\n",
    "\n",
    "    # Concatenate all node features\n",
    "    x = torch.cat(node_features, dim=1)\n",
    "\n",
    "    # Load graph-level features (targets for regression)\n",
    "    # print('  Loading graph-level features...')\n",
    "    manifold_id = int(f[\"manifold_ids\"][idx])\n",
    "    boundary_id = int(f[\"boundary_ids\"][idx])\n",
    "    relation_dim = torch.tensor(f[\"relation_dim\"][idx], dtype=float_dtype)\n",
    "    atom_count = torch.tensor(f[\"atom_count\"][idx], dtype=int_dtype)\n",
    "    num_sources = torch.tensor(f[\"num_sources\"][idx], dtype=int_dtype)\n",
    "    num_sinks = torch.tensor(f[\"num_sinks\"][idx], dtype=int_dtype)\n",
    "    dimension = int(f[\"dimension\"][()])\n",
    "\n",
    "    # print('  Loading additional matrices...')\n",
    "    # matrices\n",
    "    link_matrix = torch.tensor(\n",
    "        f[\"link_matrix\"][idx, :, :], dtype=float_dtype\n",
    "    ).to_sparse()\n",
    "    past_relations = torch.tensor(\n",
    "        f[\"past_relations\"][idx, :, :], dtype=float_dtype\n",
    "    ).to_sparse()\n",
    "    future_relations = torch.tensor(\n",
    "        f[\"future_relations\"][idx, :, :], dtype=float_dtype\n",
    "    ).to_sparse()\n",
    "\n",
    "    # print('  Creating Data object...')\n",
    "    # Create Data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index.to('cpu'),\n",
    "        edge_attr=edge_weight.unsqueeze(1).to('cpu')\n",
    "        if edge_weight.numel() > 0\n",
    "        else None,  # Not sure if this is a good idea need to add edge attributes if possible\n",
    "        # node positions as positional attributes as well\n",
    "        # pos=sprinkling,\n",
    "        y=torch.tensor([manifold_id, boundary_id, dimension], dtype=torch.long).to('cpu'),\n",
    "        # Graph-level attributes\n",
    "        manifold_id=manifold_id,\n",
    "        boundary_id=boundary_id,\n",
    "        relation_dim=relation_dim,\n",
    "        dimension=dimension,\n",
    "        atom_count=atom_count,\n",
    "        num_sources=num_sources.to('cpu'),\n",
    "        num_sinks=num_sinks.to('cpu'),\n",
    "        # sprinkling=sprinkling, # don't use this for now.\n",
    "        # Additional matrices as graph attributes. make the shitty past and future relations and all that into node attributes!\n",
    "        adjacency_matrix=adj_matrix.to('cpu'),\n",
    "        link_matrix=link_matrix.to('cpu'),\n",
    "        past_relations=past_relations.to('cpu'),\n",
    "        future_relations=future_relations.to('cpu'),\n",
    "    )\n",
    "\n",
    "    if validate:\n",
    "        data.validate()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OneHotEncodeTargets:\n",
    "    def __init__(self, manifold_classes=6, boundary_classes=3, dimension_classes=3):\n",
    "        self.manifold_classes = manifold_classes\n",
    "        self.boundary_classes = boundary_classes  \n",
    "        self.dimension_classes = dimension_classes\n",
    "        \n",
    "        # Dimension mapping: {2: 0, 3: 1, 4: 2}\n",
    "        self.dim_to_idx = {2: 0, 3: 1, 4: 2}\n",
    "        \n",
    "    def __call__(self, data: Data) -> Data:\n",
    "        # Extract the original targets\n",
    "        manifold_id = data.y[0].long() - 1  # Convert to 0-based indexing\n",
    "        boundary_id = data.y[1].long() - 1  # Convert to 0-based indexing  \n",
    "        dimension = data.y[2].long()        # Keep as is for mapping\n",
    "        \n",
    "        # Map dimension to 0-based index\n",
    "        dim_idx = self.dim_to_idx[dimension.item()]\n",
    "        \n",
    "        # Create one-hot encodings\n",
    "        manifold_onehot = F.one_hot(manifold_id, num_classes=self.manifold_classes).float()\n",
    "        boundary_onehot = F.one_hot(boundary_id, num_classes=self.boundary_classes).float()\n",
    "        dimension_onehot = F.one_hot(torch.tensor(dim_idx), num_classes=self.dimension_classes).float()\n",
    "        y_onehot = torch.cat([manifold_onehot, boundary_onehot, dimension_onehot], dim=0)\n",
    "\n",
    "        data.y_original = data.y  # Keep original for reference\n",
    "        data.y = y_onehot\n",
    "\n",
    "        data.target_info={\n",
    "            'manifold_classes': self.manifold_classes,\n",
    "            'boundary_classes': self.boundary_classes,\n",
    "            'dimension_classes': self.dimension_classes,\n",
    "            'manifold_offset': 0, \n",
    "            'boundary_offset': self.manifold_classes,\n",
    "            'dimension_offset': self.manifold_classes + self.boundary_classes,   \n",
    "            'total_classes': self.manifold_classes + self.boundary_classes + self.dimension_classes,\n",
    "        }\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(manifold_classes={self.manifold_classes}, boundary_classes={self.boundary_classes}, dimension_classes={self.dimension_classes})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_shift(data, manifold_classes=6, boundary_classes=3, dimension_classes=3) -> Data: \n",
    "    manifold_id = data.y[0].long() - 1  # conver to 0 based\n",
    "    boundary_id = data.y[1].long() - 1  # conver to 0 based\n",
    "    dimension = data.y[2].long() - 2  # conver to 0 based -> 2D is the lowest we can have\n",
    "    \n",
    "    data.y_original = data.y  # Keep original for reference\n",
    "    data.y = torch.tensor([[dimension, boundary_id, manifold_id],], dtype=torch.long)\n",
    "\n",
    "    data.target_info={\n",
    "        'manifold_classes': manifold_classes,\n",
    "        'boundary_classes': boundary_classes,\n",
    "        'dimension_classes': dimension_classes,\n",
    "        'dimension_offset': 0,   \n",
    "        'boundary_offset': dimension_classes,\n",
    "        'manifold_offset': dimension_classes + boundary_classes, \n",
    "        'total_classes': manifold_classes + boundary_classes + dimension_classes,\n",
    "    }\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input: list[str],\n",
    "        output: str,  # = root directory for processed data\n",
    "        transform: Callable[[Data], Data] | None = None,\n",
    "        pre_transform: Callable[[Data], Data] | None = None,\n",
    "        pre_filter: Callable[[Data], Data] | None = None,\n",
    "        validate_data: bool = False,\n",
    "        loader: Callable[[h5py.File, torch.dtype, torch.dtype, bool], Data] = load_graph,\n",
    "    ):\n",
    "        self.input = input\n",
    "        self._num_samples = None\n",
    "        self.validate_data = validate_data\n",
    "        self.root = output\n",
    "        self.loader = loader\n",
    "        self.root = output\n",
    "\n",
    "        if len(self.processed_file_names) > 0:\n",
    "            self.num_samples = len(self.processed_file_names)\n",
    "\n",
    "            if len(self.processed_file_names) == 0:\n",
    "                raise ValueError(\"No processed data found in the output directory.\")\n",
    "\n",
    "            if not os.path.exists(os.path.join(self.processed_dir, \"metadata.json\")):\n",
    "                raise FileNotFoundError(\n",
    "                    \"Metadata file not found in the output directory. \"\n",
    "                    \"Please ensure the dataset has been processed.\"\n",
    "                )\n",
    "\n",
    "            with open(os.path.join(self.processed_dir, \"metadata.json\"), \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                self.manifold_codes = metadata[\"manifold_codes\"]\n",
    "                self.manifold_names = metadata[\"manifolds\"]\n",
    "                self.boundaries = metadata[\"boundaries\"]\n",
    "                self.boundary_codes = metadata[\"boundary_codes\"]\n",
    "                self._num_samples = len(self.processed_file_names)\n",
    "        else:\n",
    "            if input is None or len(input) == 0:\n",
    "                raise ValueError(\"Input files must be provided for processing.\")\n",
    "            \n",
    "            with h5py.File(input[0], \"r\") as f:\n",
    "                self.manifold_codes = f[\"manifold_codes\"][()]\n",
    "                self.manifold_names = f[\"manifolds\"][()]\n",
    "                self.boundaries = f[\"boundaries\"][()]\n",
    "                self.boundary_codes = f[\"boundary_codes\"][()]\n",
    "\n",
    "            self._num_samples = 0\n",
    "            for file in self.input:\n",
    "                if not os.path.exists(file):\n",
    "                    raise FileNotFoundError(f\"Input file {file} does not exist.\")\n",
    "                with h5py.File(file, \"r\") as f:\n",
    "                    self._num_samples += f[\"num_causal_sets\"][()]\n",
    "                    print(f\"Processing file: {file}, current number of samples: {self._num_samples}\")\n",
    "\n",
    "        super().__init__(output, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_paths(self):\n",
    "        return self.input\n",
    "\n",
    "    @property\n",
    "    def output(self):\n",
    "        return self.root\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [os.path.basename(f) for f in self.input]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        if os.path.isdir(self.processed_dir) is False: \n",
    "            return []\n",
    "\n",
    "        all_files = os.listdir(self.processed_dir)\n",
    "        return [\n",
    "            f\n",
    "            for f in all_files\n",
    "            if f.startswith(\"data_\") and f.endswith(\".pt\")\n",
    "        ]\n",
    "\n",
    "    def process(self):\n",
    "        print(\"processed dir: \", self.processed_dir, len(self.processed_file_names))\n",
    "        # Convert NumPy arrays to Python lists for JSON serialization\n",
    "        if not os.path.exists(self.processed_dir) or len(self.processed_file_names) == 0: \n",
    "            d = {\n",
    "                \"manifold_codes\": [v.item() for v in self.manifold_codes],\n",
    "                \"manifolds\": [str(m) for m in self.manifold_names],\n",
    "                \"boundaries\": [str(m) for m in self.boundaries],\n",
    "                \"boundary_codes\": [v.item() for v in self.boundary_codes],\n",
    "            }\n",
    "\n",
    "            with open(os.path.join(self.processed_dir, \"metadata.json\"), \"w\") as f:\n",
    "                json.dump(d, f)\n",
    "\n",
    "            file_index = 0\n",
    "            for file in self.raw_paths:\n",
    "                if not os.path.exists(file):\n",
    "                    raise FileNotFoundError(f\"Input file {file} does not exist.\")\n",
    "                with h5py.File(file, \"r\") as f:\n",
    "                    # FIXME: this loop should be parallelized for large datasets\n",
    "                    print(f\"Processing file: {file}\")\n",
    "                    print(f\"Number of causal sets: {f['num_causal_sets'][()]} of total {self._num_samples} with current index {file_index}\")\n",
    "                    for idx in tqdm(range(f[\"num_causal_sets\"][()])):\n",
    "                        data = self.loader(\n",
    "                            f,\n",
    "                            idx,\n",
    "                            float_dtype=torch.float32,\n",
    "                            int_dtype=torch.int64,\n",
    "                            validate=self.validate_data,\n",
    "                        )\n",
    "                        if self.pre_filter is not None:\n",
    "                            if not self.pre_filter(data):\n",
    "                                continue\n",
    "                        if self.pre_transform is not None:\n",
    "                            data = self.pre_transform(data)\n",
    "                        torch.save(data.to('cpu'), os.path.join(self.processed_dir, f\"data_{file_index}.pt\"))\n",
    "                        file_index += 1\n",
    "\n",
    "    def len(self):\n",
    "        return self._num_samples\n",
    "\n",
    "    def get(self, idx):\n",
    "        # TODO: check again about the weights_only=False part\n",
    "        data = torch.load(os.path.join(self.processed_dir, f\"data_{idx}.pt\"), weights_only=False)\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch_geometric\n",
    "import os\n",
    "from torch.nn import Linear \n",
    "from torch_geometric.nn.conv import GCNConv, GATConv, SAGEConv, GraphConv, GATv2Conv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool, global_add_pool, SAGPooling, Set2Set\n",
    "import torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNBlock(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.5, gcn_type=GCNConv, batchnorm=torch.nn.Identity, activation = F.relu, gcn_kwargs=None):\n",
    "        super(GCNBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.gcn_type = gcn_type\n",
    "        self.conv = gcn_type(input_dim, output_dim, **(gcn_kwargs if gcn_kwargs else {}))\n",
    "        self.activation = activation\n",
    "        self.batch_norm = batchnorm\n",
    "\n",
    "        if input_dim != output_dim:\n",
    "            # Use 1x1 convolution for projection\n",
    "            self.projection = Linear(input_dim, output_dim, bias=False)\n",
    "        else: \n",
    "            self.projection = torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None, kwargs=None):\n",
    "        x_res = x\n",
    "        x = self.conv(x, edge_index, edge_weight=edge_weight, **(kwargs if kwargs else {}))  # Apply the GCN layer\n",
    "        x = self.batch_norm(x, )  # this is a no-op if batch normalization is not used\n",
    "        x = self.activation(x)\n",
    "        x = x + self.projection(x_res)  # skip connection\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)  # this is only applied during training\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNBackbone(torch.nn.Module): \n",
    "    def __init__(self, gcn_net: list[GCNBlock]): \n",
    "        super(GCNBackbone, self).__init__()\n",
    "        self.gcn_net = torch.nn.ModuleList(gcn_net)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None, gcn_kwargs=None):\n",
    "        out = x\n",
    "        for layer in self.gcn_net:\n",
    "            out = layer(out, edge_index, edge_weight=edge_weight, kwargs=gcn_kwargs)\n",
    "            # Note: also changed gcn_kwargs to kwargs to match GCNBlock signature\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierBlock(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        output_dim,\n",
    "        hidden_dims,\n",
    "        manifold_classes=6,\n",
    "        boundary_classes=3,\n",
    "        dimension_classes=3,\n",
    "        activation=F.relu,\n",
    "        linear_kwargs=None,\n",
    "        dim_kwargs=None,\n",
    "        boundary_kwargs=None,\n",
    "        manifold_kwargs=None,\n",
    "    ):\n",
    "        super(ClassifierBlock, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.total_classes = manifold_classes + boundary_classes + dimension_classes\n",
    "        self.manifold_classes = manifold_classes\n",
    "        self.boundary_classes = boundary_classes\n",
    "        self.dimension_classes = dimension_classes\n",
    "\n",
    "        if len(hidden_dims) == 0:\n",
    "            self.backbone = Linear(input_dim, output_dim, **(linear_kwargs[0] if linear_kwargs else {}))\n",
    "        else:\n",
    "            layers = []\n",
    "            in_dim = input_dim\n",
    "            for (i, hidden_dim) in enumerate(hidden_dims):\n",
    "                layers.append(\n",
    "                    Linear(in_dim, hidden_dim, **(linear_kwargs[i] if linear_kwargs and linear_kwargs[i] else {}))\n",
    "                )  # check again if we need the bias there, I don't think so actually...\n",
    "                layers.append(activation)\n",
    "                in_dim = hidden_dim\n",
    "\n",
    "            self.backbone = torch.nn.Sequential(*layers)\n",
    "\n",
    "            self.dim_layer = torch.nn.Linear(hidden_dim, self.dimension_classes, **(dim_kwargs if dim_kwargs else {}))\n",
    "\n",
    "            self.boundary_layer = torch.nn.Linear(hidden_dim, self.boundary_classes, **(boundary_kwargs if boundary_kwargs else {}))\n",
    "\n",
    "            self.manifold_layer = torch.nn.Linear(hidden_dim, self.manifold_classes, **(manifold_kwargs if manifold_kwargs else {}))\n",
    "\n",
    "    def forward(self, x, backbone_kwargs=None, dim_layer_kwargs=None, boundary_layer_kwargs=None, manifold_layer_kwargs=None):\n",
    "\n",
    "        x = self.backbone(\n",
    "            x, \n",
    "            **(backbone_kwargs if backbone_kwargs is not None else {})\n",
    "        )  \n",
    "\n",
    "        dim_logit = self.dim_layer(x, **(dim_layer_kwargs if dim_layer_kwargs is not None else {}))\n",
    "        boundary_logit = self.boundary_layer(x, **(boundary_layer_kwargs if boundary_layer_kwargs is not None else {}))\n",
    "        manifold_logit = self.manifold_layer(x, **(manifold_layer_kwargs if manifold_layer_kwargs is not None else {}))\n",
    "\n",
    "        return dim_logit, boundary_logit, manifold_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphFeaturesBlock(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dims, dropout=0.5, activation = F.relu, linear_kwargs=None, final_linear_kwargs=None):\n",
    "\n",
    "        super(GraphFeaturesBlock, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.activation = activation\n",
    "        self.hidden_dims = hidden_dims\n",
    "\n",
    "        if len(hidden_dims) == 0: \n",
    "            self.linear = Linear(input_dim, output_dim)\n",
    "        else: \n",
    "            layers = []\n",
    "            in_dim = input_dim\n",
    "            for (i, hidden_dim) in enumerate(hidden_dims): \n",
    "                layers.append(Linear(in_dim, hidden_dim, **(linear_kwargs[i] if linear_kwargs and linear_kwargs[i] else {})))\n",
    "                layers.append(activation)\n",
    "                in_dim = hidden_dim\n",
    "            layers.append(Linear(in_dim, output_dim, **(final_linear_kwargs if final_linear_kwargs else {})))\n",
    "            self.linear = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "basic model class to organize the other things. does the following: \n",
    "- passes input through gcn network. This is a succession of GCN blocks\n",
    "- applies graph feature network to graph level features and concatenates them with pooled node features **if** `use_graph_features = true`. \n",
    "\n",
    "- passes the result through the regression net to get out (dimension, boundary_id, manifold_id): \n",
    "```bash\n",
    "x -> gcn -> pool -> concat(_, g) -> regression -> output\n",
    "g ----------------> MLP_g(g) _|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gcn_net,\n",
    "        classifier,\n",
    "        pooling_layer,\n",
    "        use_graph_features=False,\n",
    "        graph_features_net=torch.nn.Identity,\n",
    "    ):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.gcn_net = gcn_net\n",
    "        self.classifier = classifier\n",
    "        self.graph_features_net = graph_features_net\n",
    "        self.use_graph_features = use_graph_features\n",
    "        self.pooling_layer = pooling_layer\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        edge_index,\n",
    "        batch,\n",
    "        edge_weight=None,\n",
    "        graph_features=None,\n",
    "        gcn_kwargs=None,\n",
    "    ):\n",
    "        x = self.gcn_net(\n",
    "            x, edge_index, edge_weight=edge_weight, **(gcn_kwargs if gcn_kwargs else {})\n",
    "        )\n",
    "        \n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.shape[0], dtype=torch.long, device=x.device)\n",
    "        \n",
    "        x = self.pooling_layer(x, batch)\n",
    "        if self.use_graph_features:\n",
    "            graph_features = self.graph_features_net(graph_features)\n",
    "            x = torch.cat((x, graph_features), dim=-1)  # last dim\n",
    "        manifold, boundary, dim = self.classifier(x)\n",
    "\n",
    "        return manifold, boundary, dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x_pred, y, dim_kwargs = None, boundary_kwargs=None, manifold_kwargs=None, dim_weight = 1.0, boundary_weight=1.0, manifold_weight=1.0):\n",
    "    dim_logits= x_pred[0]\n",
    "    boundary_logits = x_pred[1]\n",
    "    manifold_logits = x_pred[2]\n",
    "\n",
    "    dim_truth = y[:, 0]\n",
    "    boundary_truth = y[:, 1]\n",
    "    manifold_truth = y[:, 2]\n",
    "    \n",
    "    dim_cel = torch.nn.CrossEntropyLoss(**(dim_kwargs if dim_kwargs else {}))\n",
    "    boundary_cel = torch.nn.CrossEntropyLoss(**(boundary_kwargs if boundary_kwargs else {}))\n",
    "    manifold_cel = torch.nn.CrossEntropyLoss(**(manifold_kwargs if manifold_kwargs else {}))\n",
    "\n",
    "    loss_dim = dim_cel(dim_logits, dim_truth)\n",
    "    loss_boundary = boundary_cel(boundary_logits, boundary_truth)\n",
    "    loss_manifold = manifold_cel(manifold_logits, manifold_truth)\n",
    "\n",
    "    total_loss = loss_dim * dim_weight + loss_boundary * boundary_weight + loss_manifold * manifold_weight\n",
    "\n",
    "    return total_loss, loss_dim, loss_boundary, loss_manifold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Check that this is sensible first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, validation_loader, optimizer, loss_func, device):\n",
    "    # FIXME: this is bullshit, has no epochs and nothing!\n",
    "    training_loss = np.zeros(len(train_loader), dtype=np.float32)\n",
    "    training_loss_dim = np.zeros(len(train_loader), dtype=np.float32)\n",
    "    training_loss_boundary = np.zeros(len(train_loader), dtype=np.float32)  \n",
    "    training_loss_manifold = np.zeros(len(train_loader), dtype=np.float32)\n",
    "\n",
    "    valid_loss = np.zeros(len(validation_loader), dtype=np.float32)\n",
    "\n",
    "\n",
    "    for epoch, data in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)  # Move data to the same device as the model\n",
    "        print(data.x.shape, data.edge_index.shape, data.batch.shape)\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        total_loss, loss_dim, loss_boundary, loss_manifold = loss_func(out, data.y)  # Assuming data.y contains the target values\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss[epoch] = total_loss.item()\n",
    "        training_loss_dim[epoch] = loss_dim.item()\n",
    "        training_loss_boundary[epoch] = loss_boundary.item()\n",
    "        training_loss_manifold[epoch] = loss_manifold.item()\n",
    "\n",
    "        mean_validation_loss = 0.0\n",
    "        for data in validation_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                data = data.to(device) \n",
    "                out = model(data.x, data.edge_index, data.batch)\n",
    "                total_loss, _, _, _ = loss_func(out, data.y)\n",
    "                mean_validation_loss += total_loss.item()\n",
    "        mean_validation_loss /= len(validation_loader)\n",
    "        print(f\"Epoch: {epoch}, Validation Loss: {mean_validation_loss:.4f}\")\n",
    "        valid_loss[epoch] = total_loss.item()\n",
    "\n",
    "    return training_loss, valid_loss\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.to(device) \n",
    "            dim, boundary, manifold = model(data.x, data.edge_index, data.batch)\n",
    "            \n",
    "            dim = torch.argmax(dim, dim=1) # this is enough here, because the encodings are concruential to the indices\n",
    "            boundary = torch.argmax(boundary, dim=1) # this is enough here, because the encodings are concruential to the indices\n",
    "            manifold = torch.argmax(manifold, dim=1) # this is enough here, because the encodings are concruential to the indices\n",
    "\n",
    "            total += data.y.size(0)\n",
    "            correct += (dim == data.y).sum().item()\n",
    "            correct += (boundary == data.y).sum().item()\n",
    "            correct += (manifold == data.y).sum().item()\n",
    "\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Actual training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### get cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### define the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath  = os.path.join(os.path.home(), \"data\", \"causal_sets\")\n",
    "datapath = os.path.join(\"/mnt\", \"dataLinux\", \"machinelearning_data\", \"QuantumGrav\", \"causal_sets\")\n",
    "files = [\n",
    "    os.path.join(datapath, \"cset_data_min=300_max=650_N=25000_d=2.h5\"),\n",
    "    os.path.join(datapath, \"cset_data_min=300_max=650_N=25000_d=3.h5\"),\n",
    "    os.path.join(datapath, \"cset_data_min=300_max=650_N=25000_d=4.h5\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = CsDataset(\n",
    "    input=files,\n",
    "    output=os.path.join(datapath),\n",
    "    pre_transform=target_shift,  # maybe add some augmentation stuff here later\n",
    "    pre_filter=None,  # Filter data before loading, e.g., based on manifold or boundary or something like that\n",
    "    validate_data=True,  # Validate data after loading\n",
    "    loader=load_graph,  # Custom loader function\n",
    ").shuffle()\n",
    "\n",
    "# train_size = int(math.ceil(0.8 * len(dset)))\n",
    "# test_size = int(math.ceil(0.1 * len(dset)))\n",
    "# val_size = len(dset) - train_size - test_size\n",
    "\n",
    "train_size = 10*64\n",
    "test_size = 5*64\n",
    "val_size= 5*64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dset[0:train_size],\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    # prefetch_factor=5,\n",
    ")\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dset[train_size : train_size + test_size],\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    # prefetch_factor=5,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dset[train_size + test_size: train_size + test_size + val_size],\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    # pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    # prefetch_factor=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### define a new model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_features = dset[0].x.shape[1]  # Number of node features\n",
    "n_edge_features = dset[0].edge_attr.shape[1] if dset[0].edge_attr is not None else 0  # Number of edge features\n",
    "\n",
    "normalizer = torch.nn.BatchNorm1d\n",
    "conv_layer = GCNConv  # You can change this to GATConv, SAGEConv, etc. as needed\n",
    "\n",
    "conv1 = GCNBlock(\n",
    "    input_dim=n_node_features,\n",
    "    output_dim=128,\n",
    "    dropout=0.3,\n",
    "    batchnorm=normalizer(128),  # Use BatchNorm1d for batch normalization\n",
    "    gcn_type=conv_layer,  # You can change this to GATConv, SAGEConv, etc.\n",
    "    activation=torch.nn.ReLU(),\n",
    "    gcn_kwargs={\"cached\": True}  # Example of passing additional arguments to the GCN layer\n",
    ")\n",
    "\n",
    "conv2 = GCNBlock(\n",
    "    input_dim=128,\n",
    "    output_dim=256,\n",
    "    dropout=0.3,\n",
    "    batchnorm=normalizer(256),  # Use BatchNorm1d for batch normalization\n",
    "    gcn_type=conv_layer,  # You can change this to GATConv, SAGEConv, etc.\n",
    "    activation=torch.nn.ReLU(),\n",
    "    gcn_kwargs={\"cached\": True}  # Example of passing additional arguments to the GCN layer\n",
    ")\n",
    "\n",
    "conv3 = GCNBlock(\n",
    "    input_dim=256,\n",
    "    output_dim=128,\n",
    "    dropout=0.3,\n",
    "    batchnorm=normalizer(128),  # Use BatchNorm1d for batch normalization\n",
    "    gcn_type=conv_layer,  # You can change this to GATConv, SAGEConv, etc.\n",
    "    activation=torch.nn.ReLU(),\n",
    "    gcn_kwargs={\"cached\": True}  # Example of passing additional arguments to the GCN layer\n",
    ")\n",
    "\n",
    "\n",
    "gcn_backbone = GCNBackbone([conv1, conv2, conv3])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ClassifierBlock(\n",
    "    input_dim=128,  # Output dimension of the last GCN layer\n",
    "    output_dim=3,  # Assuming you want to predict manifold_id, boundary_id, and dimension\n",
    "    hidden_dims=[64, 32],  # Example hidden dimensions\n",
    "    manifold_classes=6,\n",
    "    boundary_classes=3,\n",
    "    dimension_classes=3,\n",
    "    activation=torch.nn.ReLU(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer = global_mean_pool  # You can change this to global_max_pool, global_add_pool, etc.\n",
    "\n",
    "model = GCNModel(\n",
    "    gcn_net=gcn_backbone,\n",
    "    classifier=classifier,\n",
    "    pooling_layer=pooling_layer,\n",
    "    use_graph_features=False,  # Set to True if you want to use graph features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Visualize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn((first.x.shape[0], n_node_features), dtype=torch.float32)  \n",
    "# out = model(x, first.edge_index, first.batch)\n",
    "\n",
    "# dot = torchviz.make_dot(\n",
    "#     out,\n",
    "#     params=dict(model.named_parameters()),\n",
    "#     show_attrs=False,  # Hide detailed attributes\n",
    "#     show_saved=False,  # Hide saved tensors\n",
    "# )\n",
    "\n",
    "# dot.render(\"model_visualization\", format=\"pdf\", cleanup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "total_training_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "dim_training_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "boundary_training_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "manifold_training_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "\n",
    "total_validation_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "dim_validation_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "boundary_validation_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "manifold_validation_loss = np.zeros((epochs, 2), dtype=np.float32)\n",
    "\n",
    "\n",
    "lossfunc = criterion  # Use the custom criterion defined above\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_training_loss_bt = np.zeros((len(train_loader), 2), dtype=np.float64)\n",
    "    dim_training_loss_bt = np.zeros((len(train_loader), 2), dtype=np.float64)\n",
    "    boundary_training_loss_bt = np.zeros((len(train_loader), 2), dtype=np.float64)\n",
    "    manifold_training_loss_bt = np.zeros((len(train_loader), 2), dtype=np.float64)\n",
    "\n",
    "    model.train()\n",
    "    for batch, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch} Training\")):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        total_loss, loss_dim, loss_boundary, loss_manifold = lossfunc(out, data.y)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_training_loss_bt[batch] = total_loss.item()\n",
    "        dim_training_loss_bt[batch] = loss_dim.item()\n",
    "        boundary_training_loss_bt[batch] = loss_boundary.item()\n",
    "        manifold_training_loss_bt[batch] = loss_manifold.item()\n",
    "\n",
    "    mean_total_loss = total_training_loss_bt.mean()\n",
    "    mean_dim_loss = dim_training_loss_bt.mean()\n",
    "    mean_boundary_loss = boundary_training_loss_bt.mean()\n",
    "    mean_manifold_loss = manifold_training_loss_bt.mean()\n",
    "\n",
    "    std_total_loss = total_training_loss_bt.std()\n",
    "    std_dim_loss = dim_training_loss_bt.std()\n",
    "    std_boundary_loss = boundary_training_loss_bt.std()\n",
    "    std_manifold_loss = manifold_training_loss_bt.std()\n",
    "\n",
    "    total_training_loss[batch, 0] = mean_total_loss\n",
    "    dim_training_loss[batch, 0] = mean_dim_loss\n",
    "    boundary_training_loss[batch, 0] = mean_boundary_loss\n",
    "    manifold_training_loss[batch, 0] = mean_manifold_loss   \n",
    "\n",
    "    total_training_loss[batch, 1] = std_total_loss\n",
    "    dim_training_loss[batch, 1] = std_dim_loss\n",
    "    boundary_training_loss[batch, 1] = std_boundary_loss\n",
    "    manifold_training_loss[batch, 1] = std_manifold_loss\n",
    "\n",
    "    # Validation step\n",
    "\n",
    "    total_validation_loss_bt = np.zeros((len(val_loader), 2), dtype=np.float64)\n",
    "    dim_validation_loss_bt = np.zeros((len(val_loader), 2), dtype=np.float64)\n",
    "    boundary_validation_loss_bt = np.zeros((len(val_loader), 2), dtype=np.float64)\n",
    "    manifold_validation_loss_bt = np.zeros((len(val_loader), 2), dtype=np.float64)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, data in enumerate(tqdm(val_loader, desc=f\"Epoch {epoch} Validation\")):\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            total_loss, loss_dim, loss_boundary, loss_manifold = lossfunc(out, data.y)\n",
    "\n",
    "            total_validation_loss_bt[batch] = total_loss.item()\n",
    "            dim_validation_loss_bt[batch] = loss_dim.item()\n",
    "            boundary_validation_loss_bt[batch] = loss_boundary.item()\n",
    "            manifold_validation_loss_bt[batch] = loss_manifold.item()\n",
    "\n",
    "        mean_val_total_loss = total_validation_loss_bt.mean()\n",
    "        mean_val_dim_loss = dim_validation_loss_bt.mean()\n",
    "        mean_val_boundary_loss = boundary_validation_loss_bt.mean()\n",
    "        mean_val_manifold_loss = manifold_validation_loss_bt.mean()\n",
    "\n",
    "        std_val_total_loss = total_validation_loss_bt.std()\n",
    "        std_val_dim_loss = dim_validation_loss_bt.std()\n",
    "        std_val_boundary_loss = boundary_validation_loss_bt.std()\n",
    "        std_val_manifold_loss = manifold_validation_loss_bt.std()\n",
    "\n",
    "        total_validation_loss[batch, 0] = mean_val_total_loss\n",
    "        dim_validation_loss[batch, 0] = mean_val_dim_loss\n",
    "        boundary_validation_loss[batch, 0] = mean_val_boundary_loss\n",
    "        manifold_validation_loss[batch, 0] = mean_val_manifold_loss\n",
    "\n",
    "        total_validation_loss[batch, 1] = std_val_total_loss\n",
    "        dim_validation_loss[batch, 1] = std_val_dim_loss\n",
    "        boundary_validation_loss[batch, 1] = std_val_boundary_loss\n",
    "        manifold_validation_loss[batch, 1] = std_val_manifold_loss\n",
    "\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(\n",
    "        f\"  training loss: {mean_total_loss:.4f} ± {std_total_loss:.4f}, Dim : {mean_dim_loss:.4f} ± {std_dim_loss:.4f}, Boundary : {mean_boundary_loss:.4f} ± {std_boundary_loss:.4f}, Manifold : {mean_manifold_loss:.4f} ± {std_manifold_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"  validation loss: {mean_val_total_loss:.4f} ± {std_val_total_loss:.4f}, Dim : {mean_val_dim_loss:.4f} ± {std_val_dim_loss:.4f}, Boundary : {mean_val_boundary_loss:.4f} ± {std_val_boundary_loss:.4f}, Manifold : {mean_val_manifold_loss:.4f} ± {std_val_manifold_loss:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- [ ] gpu utilization low \n",
    "- [ ] implement early stopping \n",
    "- [ ] performance improvements \n",
    "- [ ] experiments with different models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
