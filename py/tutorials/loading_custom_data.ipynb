{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Creating graph datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## creating In Memory datasets\n",
    "\n",
    "we need 4 fundamental methods: \n",
    "- raw_file_names() -> list of file names in `raw_dir` for raw data used to skip the download \n",
    "- processed_file_names -> list of file name sin `processed_dir` to skip the processing \n",
    "- download() downloads raw data into raw_dir() --> donÂ´t implement if no download necessary \n",
    "- process() process raw data and save it into processed dir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "the 'process' method is the most important one. this creates a list of 'Data' objects that are saved into 'processed_dir' then. Data objects will be collated into one giant `Data` object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch_geometric.data import InMemoryDataset, download_url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset): \n",
    "    def __init__(self, root, transform=None, pre_transform= None, pre_filter = None): \n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self): \n",
    "        return ['data1.pt', 'data2.pt']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self): \n",
    "        return ['data.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        url = 'https://example.com/data.zip'\n",
    "        download_url(url, self.raw_dir)\n",
    "\n",
    "    def process(self): \n",
    "        data_list = [...]\n",
    "        \n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        self.save(data_list, self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "in my case, I would need to use hdf5 or similar. Zarr could work, but Arrow does not, it's ill suited for this purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Creating 'larger' Datasets\n",
    "\n",
    "if stuff does not fit into memory, we can use the `Dataset` class. This follows closely the concept of the torchvision datasets. It expects the methods len() and get() to be implemented. get() implements the logic to get a single graph, len() gets the number of examples in the dataset. Works in much the same way as the Julia datasets we already have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp \n",
    "from torch_geometric.data import Dataset \n",
    "\n",
    "class MyOwnOnDiskDataset(Dataset): \n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None): \n",
    "        pass \n",
    "    \n",
    "    @property \n",
    "    def raw_file_names(self): \n",
    "        return ['data1.pt', 'data2.pt']\n",
    "    \n",
    "    @property \n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        url = 'https://example.com/data.zip'\n",
    "        download_url(url, self.raw_dir)\n",
    "\n",
    "    def process(self): \n",
    "        idx = 0\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path\n",
    "            data = Data(...) # TODO\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data): \n",
    "                continue \n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "            idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data =torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Here, each graph data object gets saved individually in process(), and is manually loaded in get(). We might want to cache some for ease of use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Use HDF5 or Zarr if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Loading Graphs from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import download_url, extract_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_zip(download_url(url, '.'), './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = './ml-latest-small/movies.csv'\n",
    "rating_path = './ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.read_csv(movie_path).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.read_csv(rating_path).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
