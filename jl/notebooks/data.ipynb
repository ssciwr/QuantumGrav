{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg \n",
    "Pkg.activate(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "addprocs(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin \n",
    "    import QuantumGrav as QG\n",
    "    import Arrow\n",
    "    import Distributions\n",
    "    import JLD2\n",
    "    import ProgressMeter: @showprogress\n",
    "    import Flux\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Generate some dummy data first. This is only there to demonstrate the usage of the `Dataset` type with the `Flux.Dataloader` type, so the details of data generation donÂ´t matter here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = QG.DataGeneration.generate_data_for_manifold(\n",
    "    dimension = 2,\n",
    "    seed = 329478,\n",
    "    num_datapoints = 128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:manifold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "create a bunch of files, here with the same data just for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = tempdir()\n",
    "for i in 1:10   \n",
    "    Arrow.write(joinpath(tempdir(), \"testdata$(i).arrow\"), data)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD2.jldopen(joinpath(dir, \"testdata.jld2\"), \"w\") do file\n",
    "    for i in 1:10\n",
    "        for k in keys(data)\n",
    "            file[\"chunk$(i)/$(k)\"] = data[k]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Create a dataset from the thing. The dataset uses lazy loading to fetch data on demand, and caches some of it to allow for a compromise between memory usage and speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = QG.DataLoader.Dataset(\n",
    "    dir, \n",
    "    mode = \"arrow\",\n",
    "    cache_size = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsetjld = QG.DataLoader.Dataset(\n",
    "    dir, \n",
    "    mode = \"jld2\",\n",
    "    cache_size = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Use the created dataset with a Flux dataloader (itself based on `MLUtils.jl`). We use shuffle and confirm that the data is reordered in the first batch. This can now be used to write a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x.manifold for x in dset[1:32]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_loader = Flux.DataLoader(\n",
    "    dset,\n",
    "    batchsize = 32,\n",
    "    shuffle = true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [first(shuffle_loader)[i].manifold for i in 1:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Data is shuffled. Yay! We can do the same thing without shuffling, and should get the data in the order it is in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_loader = Flux.DataLoader(\n",
    "    dset,\n",
    "    batchsize = 32,\n",
    "    shuffle = false,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [first(deterministic_loader)[i].manifold for i in 1:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "It's ordered now. Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We can use some features from `MLUtils.jl` to split the data into train, test and validation loaders for example. note that the splits need to b in (0,1) (exclusive intervals!) and that the `splitob` function return an additional one for the last index that should be empty if the split fractions sum to 1, otherwise the last one contains the leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = Flux.DataLoader.(Flux.splitobs(dset, at=(0.5, 0.3, 0.2))[1:3], \n",
    "    batchsize = 16,\n",
    "    shuffle = true,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "data loaders should cover the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "(length(train_loader) + length(valid_loader) + length(test_loader)) * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "(length(train_loader) + length(valid_loader) + length(test_loader)) * 16 >= length(dset) # >= because the last batch may be smaller than the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "For k-fold cross validation, we can use the `kfolds` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x_train, x_val) in Flux.kfolds(dset, 5)\n",
    "    println(\"Training set size: \", length(x_train))\n",
    "    println(\"Validation set size: \", length(x_val))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "By default the folds are created using static splits. Use `shuffleobs` to randomly assign observations to the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x_train, x_val) in Flux.kfolds(Flux.shuffleobs(dset), 5)\n",
    "    println(\"Training set size: \", length(x_train))\n",
    "    println(\"Validation set size: \", length(x_val))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "There is a lot more than this. Go to the `MLUtils.jl` documentation to learn more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## actual data generation for manifold like csets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nothing \n",
    "train_loader = nothing\n",
    "valid_loader = nothing\n",
    "test_loader = nothing\n",
    "dset = nothing\n",
    "dsetjld = nothing\n",
    "shuffle_loader = nothing\n",
    "GC.gc() # Force garbage collection to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "large = d -> Distributions.Uniform(0.5*10^(d + 1), 2* 10^(d + 1))\n",
    "interm = d -> Distributions.Uniform(3*10^d, 7* 10^d)\n",
    "small = d -> Distributions.Uniform(0.5*10^d, 2.5* 10^d)\n",
    "tiny = d -> Distributions.Uniform(0.1*10^(d), 0.25* 10^(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "JLD2 in a single process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distributed.nprocs(), Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = joinpath(tempdir(), \"testdata\")\n",
    "mkdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "JLD2.jldopen(joinpath(dir, \"manifold_like_small.jld2\"), \"w\"; compress=true) do file\n",
    "    @showprogress for i in 1:2^2\n",
    "\n",
    "        data = QG.DataGeneration.generate_data_for_manifold(\n",
    "            dimension = 2,\n",
    "            seed = 329478,\n",
    "            num_datapoints = 128,\n",
    "            choose_num_events = small\n",
    "        )\n",
    "\n",
    "        for k in keys(data)\n",
    "            file[\"chunk$(i)/$(k)\"] = data[k]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Arrow files with multiple processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = joinpath(\"/\", \"mnt\", \"dataLinux\", \"machinelearning_data\", \"QuantumGrav\", \"interm\")\n",
    "\n",
    "if !isdir(dir)\n",
    "    mkdir(dir)\n",
    "end\n",
    "\n",
    "@showprogress @distributed for i in 1:2^4\n",
    "\n",
    "    if isfile(joinpath(dir, \"chunk$(i).arrow\"))\n",
    "        throw(ArgumentError(\"File chunk$(i).arrow already exists in $dir.\"))\n",
    "    end\n",
    "\n",
    "    data = QG.DataGeneration.generate_data_for_manifold(\n",
    "                dimension = 2,\n",
    "                seed = 329478,\n",
    "                num_datapoints = 2^12,\n",
    "                choose_num_events = interm\n",
    "            )\n",
    "\n",
    "    Arrow.write(\n",
    "                joinpath(dir, \"chunk$(i).arrow\"),\n",
    "                data,\n",
    "                compress = :zstd,\n",
    "            )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
